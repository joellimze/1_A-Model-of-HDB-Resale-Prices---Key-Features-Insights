{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Modelling HDB Resale Prices </b>\n",
    "---\n",
    "### <b> Notebook 2: Data Processing </b>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Project Overview / Objectives </b>\n",
    "\n",
    "* Build a model that predicts the resale price of public housing (i.e., Housing Development Board (HDB)) apartments in Singapore\n",
    "    * Evaluate the model's predictive ability against unseen \"test\" data, via a Kaggle submission\n",
    "* Separably identify key features associated with resale prices - by quantifying their importance from a statistical and practical viewpoint\n",
    "\n",
    "<br>\n",
    "<b> Notebook Overview </b>\n",
    "\n",
    "* The codes in this notebook perform the following data processing functions:\n",
    "    * <b>'Simulated Test' dataset creation</b> \n",
    "    * <b>Data cleaning</b>: to exclude outliers, manage missing values\n",
    "    * <b>Feature engineering</b>: to construct additional features hypothesized to be related to resale prices\n",
    "    * <b>Feature retention</b>: to focus on features hypothesized to be related to resale prices\n",
    "    * <b>Data scaling</b>: scaling of numeric features required for implementing regression regularisation techniques\n",
    "\n",
    "<br>\n",
    "<b> Notebook Structure </b>\n",
    "\n",
    "* Part 1: Import Data, Create 'Simulated Test' Dataset\n",
    "* Part 2: Define Functions: Data Cleaning \n",
    "* Part 3: Define Functions: Feature Engineering\n",
    "* Part 4: Define Functions: Others\n",
    "* Part 5: Perform Data Processing, Export Processed Data as CSV Files\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b>Imports & Installations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### <b> Part 1: Import Data, Create Simulated Test Dataset </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Overview (Recap)</b>\n",
    "\n",
    "Data on HDB resale prices over ~ 9 years (2012-03 to 2021-04), split into:\n",
    "\n",
    "* <b>Training Dataset</b> [train.csv]: ~ 150,000 observations (resale price data: present)\n",
    "* <b>Testing Dataset</b> [test.csv]: ~ 16,500 observations   (resale price data: masked)\n",
    "    * *Resale price data has been intentionally masked*\n",
    "    * *Procedurally, a trained model is meant to be applied on the \"kaggle testing\" dataset, and its performance evaluated via a Kaggle submission*\n",
    "\n",
    "<br>\n",
    "<b>Background: Creating a Simulated Test Dataset</b>\n",
    "\n",
    "* A 'Simulated Test' dataset will be subtracted from the \"training dataset [train.csv]\" to aid with model evaluation prior to its application to the \"testing dataset [test.csv]\" (for Kaggle submission)\n",
    "* Creation of the 'Simulated Test' dataset will precede the formulation of data cleaning procedures, to prevent data leakage across 'Training'-'Simulated Test'-'Testing' datasets\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<b>(a) Import Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Raw Data\n",
    "df_train_init = pd.read_csv(\"1_Data/train.csv\", dtype={41:str})\n",
    "df_test = pd.read_csv(\"1_Data/test.csv\", dtype={40:str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) Create 'Simulated Test' Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 'Simulated Test' Dataset from \"Training\" Dataset\n",
    "\n",
    "# 1. Specify X and y Features\n",
    "features = [feature for feature in df_train_init.columns]\n",
    "features.remove(\"resale_price\")\n",
    "\n",
    "X = df_train_init[features]\n",
    "y = df_train_init[\"resale_price\"]\n",
    "\n",
    "# 2. Subtract 'Simulated Test' Dataset \n",
    "X_train, X_test_sim, y_train, y_test_sim = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Concatenate X and y elements of 'Simulated Test' and 'Train' Datasets\n",
    "df_train    = pd.concat([y_train, X_train], axis=1)\n",
    "df_test_sim = pd.concat([y_test_sim, X_test_sim], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### <b> Part 2: Define Functions: Data Cleaning  </b>\n",
    "\n",
    "Data Cleaning Functions Required\n",
    "\n",
    "* <b>Fomatting</b>: Convert column names to lowercase\n",
    "* <b>Floor Area</b>: Exclude outliers by “Flat Type-Model”\n",
    "* <b>Accessibility to Amenities</b>: Perform row-wise deletion of observations with missing values related to \"distance to nearest mall\", since these form an insignificant proportion of all observations (~0.6%)\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b>(a) Define Function: Convert Column Names to Lowercase</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Convert Column Names to Lowercase\n",
    "def lowercase_column_names(dataframe):\n",
    "    dataframe.columns = dataframe.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) Define Function: Exclude Outliers by “Flat Type-Model”</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build Static Dictionary of Reasonable Bounds by 'Flat Type-Model' based on \"X_train\"\n",
    "\n",
    "# Reference: Notebook \"1_EDA\" -> Hypothesis (1) : Apartment's Floor Area is Positively Related with Resale Price -> (c) Data Cleaning : Floor Area (Square Meters)\n",
    "# Reasonable Bound (By Flat Type-Model): \"resonable bound\" = [q1 - (1 x IQR) , q3 - (1 x IQR) ]\n",
    "\n",
    "# Add Column: Flat Type-Model \n",
    "X_train[\"flat_type_model\"] = X_train[\"flat_type\"] + \" \" + X_train[\"flat_model\"]\n",
    "flat_type_model_list = [type for type in X_train[\"flat_type_model\"].unique()]\n",
    "flat_type_model_list.sort()\n",
    "\n",
    "# Add Dictionary: Reasonable Bounds by 'Flat Type-Model'\n",
    "floor_area_bounds = {flat_type_model:[ ] for flat_type_model in flat_type_model_list}\n",
    "\n",
    "for flat_type_model in flat_type_model_list:\n",
    "    q1 = X_train.loc[(X_train[\"flat_type_model\"]==flat_type_model), [\"floor_area_sqm\"]].quantile(0.25)[0]\n",
    "    q3 = X_train.loc[(X_train[\"flat_type_model\"]==flat_type_model), [\"floor_area_sqm\"]].quantile(0.75)[0]   \n",
    "    iqr = q3 - q1\n",
    "\n",
    "    threshold = 1.0\n",
    "    lower_bound = round(q1 - (threshold)*(iqr), 0)\n",
    "    upper_bound = round(q3 + (threshold)*(iqr), 0)\n",
    "\n",
    "    floor_area_bounds[flat_type_model].append(lower_bound)\n",
    "    floor_area_bounds[flat_type_model].append(upper_bound)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Function: Exclude Floor Area Outliers\n",
    "\n",
    "def floor_area_excl_outliers(dataframe):\n",
    "\n",
    "    # Add Column: Flat Type-Model \n",
    "    dataframe[\"flat_type_model\"] = dataframe[\"flat_type\"] + \" \" + dataframe[\"flat_model\"]\n",
    "\n",
    "    # Exclude Floor Area Outliers\n",
    "    for flat_type_model,bounds in floor_area_bounds.items():\n",
    "        lower_bound = bounds[0]\n",
    "        upper_bound = bounds[1]\n",
    "        \n",
    "        dataframe.drop(dataframe[(dataframe[\"flat_type_model\"]==flat_type_model) & (dataframe[\"floor_area_sqm\"]>upper_bound)].index, inplace=True)\n",
    "        dataframe.drop(dataframe[(dataframe[\"flat_type_model\"]==flat_type_model) & (dataframe[\"floor_area_sqm\"]<lower_bound)].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(c) Define Function: Perform Row-Wise Deletion of Observations with Missing Values Related to \"Distance to Nearest Mall\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Perform Row-Wise Deletion of Observations with Missing Values Related to \"Distance to Nearest Mall\"\n",
    "\n",
    "# Reference: Notebook \"1_EDA\" -> Hypothesis (7) : Accessibility to Amenities is Positively Related to Resale Price -> (c) Data Cleaning\n",
    "# Treatment of Missing Values: Row-wise deletion of observations \n",
    "\n",
    "def mall_nearest_distance_excl_missing_obs(dataframe):\n",
    "    dataframe.drop(dataframe[(dataframe[\"mall_nearest_distance\"]!=dataframe[\"mall_nearest_distance\"])].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(d) Define Function: Cleaning Procedures (Consolidated)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Cleaning Procedures (Consolidated)\n",
    "\n",
    "def clean_data(dataframe):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    # Cleaning Procedures\n",
    "    lowercase_column_names(dataframe)\n",
    "    floor_area_excl_outliers(dataframe)\n",
    "    mall_nearest_distance_excl_missing_obs(dataframe)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### <b> Part 3: Define Functions: Feature Engineering  </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>(a) Simple Features</b>\n",
    "\n",
    "* <b>Floor Area</b>: (Floor Area)^2\n",
    "* <b>Floor Level</b>: (Floor Level)^2\n",
    "* <b>Exceptional Flat Types</b>: \"DBSS\", \"Terrace\", \"Mansionette/Loft\", \"Duxton S-Type\" Dummies\n",
    "* <b>Remaining Lease Period</b>: (Remaining Lease Period)^2\n",
    "\n",
    "* <b>Apartment's Neighbour Composition</b>\n",
    "    * (a) If Apartment Block has Rental Units\n",
    "    * (b) Apartment Block’s ‘5-Room & Larger’ Flat Type Proportion - Categorical: (i) [0-0.25] %. (ii) (0.25-0.50] %, (iii) (0.50-0.75] %, (iv) (0.75-1] %\n",
    "\n",
    "* <b>Accessibility to Transport Infrastructure</b>: \n",
    "    * (a) Nearest MRT Station: (i) within 500m (Walking Distance), (ii) between 500 to 1000m , (iii) beyond 1000m\n",
    "    * (b) Nearest MRT Station: (i) train + bus interchange, (ii) train-only interchange, (iii) bus-only interchange, (iv) not a train/bus interchange \n",
    "    * (c) Nearest Bus Stop within Close Proximity (150m)\n",
    "\n",
    "* <b>Accessibility to Amenities</b>: \n",
    "    * (a) Nearest Mall: (i) within 500m (Walking Distance), (ii) between 500 to 1000m , (iii) beyond 1000m\n",
    "    * (b) Nearest Hawker Centre: (i) within 500m (Walking Distance), (ii) between 500 to 1000m , (iii) beyond 1000m\n",
    "    * (c) Nearest Hawker Centre's Size (No. of Food & Market Stalls): (i) small (<=100 stalls), (ii) large (>100 stalls)\n",
    "\n",
    "* <b>Unobserved Area-based Features</b>: “Town” Dummies\n",
    "* <b>Time-based Events</b>: “Transaction Year” Dummies\n",
    "\n",
    "<b>(b) Complex Features</b>\n",
    "\n",
    "* <b>Accessibility to the CBD</b>: Travel Cost to the CBD via the MRT Network\n",
    "\n",
    "* <b>Accessibility to ‘Branded’ Schools</b>: \n",
    "    * (a) Number of ‘Branded’ primary schools: (i) within 1 km, (ii) between 1km to 2km\n",
    "    * (b) Number of ‘Branded’ secondary schools: (i) within 1 km, (ii) between 1km to 2km\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> (a) Define Functions: Engineer Simple Features </b>\n",
    "\n",
    "Note: Constructing One-Hot Encoded Features\n",
    "\n",
    "* The construction of two simple features (\"Town\", \"Transaction Year\" dummies) requires representing categories within a categorical data column as a set of dummies\n",
    "* However, the list of categories within the \"train\", \"simulated test\", and \"test\" datasets may be different\n",
    "* To [enforce feature space consistency](https://albertum.medium.com/preprocessing-onehotencoder-vs-pandas-get-dummies-3de1f3d77dcc) required for a model trained on \"train\" data to produce predictions on the \"simulated test\" and \"test\" datasets – Sklearn’s \"OneHotEncoder\" will be used to save category labels from the \"train\" dataset (via \"fit_transform\"), before applying these to the \"simulated test\" and \"test\" datasets (via \"transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Engineer Simple Features\n",
    "\n",
    "def engineer_features_simple(dataframe):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    # (a) Floor Area\n",
    "    dataframe[\"floor_area_sqm_2\"] = dataframe[\"floor_area_sqm\"]**2\n",
    "\n",
    "    # (b) Floor Level\n",
    "    dataframe[\"floor_level_mid\"]   = dataframe[\"mid\"]\n",
    "    dataframe[\"floor_level_mid_2\"] = dataframe[\"mid\"]**2\n",
    "\n",
    "    # (c) Exceptional Flat Types\n",
    "    dataframe[\"flat_type_dbss\"]            = (dataframe[\"flat_model\"].str.contains(\"DBSS\")).astype(int)\n",
    "    dataframe[\"flat_type_terrace\"]         = (dataframe[\"flat_model\"].str.contains(\"Terrace\")).astype(int)\n",
    "    dataframe[\"flat_type_maisonette_loft\"] = (dataframe[\"flat_model\"].str.contains(\"Maisonette\") | dataframe[\"flat_model\"].str.contains(\"Loft\")).astype(int)\n",
    "    dataframe[\"flat_type_duxton_s1_s2\"]    = (dataframe[\"flat_model\"].str.contains(\"Type S1\") | dataframe[\"flat_model\"].str.contains(\"Type S2\")).astype(int)\n",
    "    \n",
    "    # (d) Remaining Lease Period\n",
    "    dataframe[\"remaining_lease_years\"]   = 99 - (dataframe[\"tranc_year\"] - dataframe[\"lease_commence_date\"]) \n",
    "    dataframe[\"remaining_lease_years_2\"] = dataframe[\"remaining_lease_years\"]**2\n",
    "\n",
    "\n",
    "    # (e) Apartment's Neighbour Composition\n",
    "\n",
    "    ## 1. If Apartment Block has Rental Units\n",
    "    dataframe[\"blk_rental_present\"] = ((dataframe[\"1room_rental\"] + dataframe[\"2room_rental\"] + dataframe[\"3room_rental\"] + dataframe[\"other_room_rental\"])>0).astype(int)\n",
    "\n",
    "    ## 2. Apartment Block’s '5-Room & Larger' Flat Type Proportion\n",
    "    dataframe[\"blk_5rm_abv_p\"]            = (dataframe[\"5room_sold\"] + dataframe[\"exec_sold\"] + dataframe[\"multigen_sold\"])/dataframe[\"total_dwelling_units\"]\n",
    "    dataframe[\"blk_5rm_abv_p_frm000_025\"] = ((dataframe[\"blk_5rm_abv_p\"]>=0.00) & (dataframe[\"blk_5rm_abv_p\"]<=0.25)).astype(int)\n",
    "    dataframe[\"blk_5rm_abv_p_abv025_050\"] = ((dataframe[\"blk_5rm_abv_p\"]>0.25)  & (dataframe[\"blk_5rm_abv_p\"]<=0.50)).astype(int)\n",
    "    dataframe[\"blk_5rm_abv_p_abv050_075\"] = ((dataframe[\"blk_5rm_abv_p\"]>0.50)  & (dataframe[\"blk_5rm_abv_p\"]<=0.75)).astype(int)\n",
    "    dataframe[\"blk_5rm_abv_p_abv075_100\"] = ((dataframe[\"blk_5rm_abv_p\"]>0.75)  & (dataframe[\"blk_5rm_abv_p\"]<=1.00)).astype(int)\n",
    "\n",
    "\n",
    "    # (f) Accessibility to Transport Infrastructure\n",
    "\n",
    "    ## 1. Nearest MRT Station: Distance\n",
    "    dataframe[\"mrt_nearest_frm000_500\"]  = ((dataframe[\"mrt_nearest_distance\"]>=0) & (dataframe[\"mrt_nearest_distance\"]<=500)).astype(int)\n",
    "    dataframe[\"mrt_nearest_abv500_1000\"] = ((dataframe[\"mrt_nearest_distance\"]>500) & (dataframe[\"mrt_nearest_distance\"]<=1000)).astype(int)\n",
    "    dataframe[\"mrt_nearest_abv1000\"]     = (dataframe[\"mrt_nearest_distance\"]>1000).astype(int)\n",
    "\n",
    "    ## 2. Nearest MRT Station: Interchange Status\n",
    "    dataframe[\"mrt_nearest_interchange_train_bus\"]  = ((dataframe[\"mrt_interchange\"]==1) & (dataframe[\"bus_interchange\"]==1)).astype(int)\n",
    "    dataframe[\"mrt_nearest_interchange_train_only\"] = ((dataframe[\"mrt_interchange\"]==1) & (dataframe[\"bus_interchange\"]==0)).astype(int)\n",
    "    dataframe[\"mrt_nearest_interchange_bus_only\"]   = ((dataframe[\"mrt_interchange\"]==0) & (dataframe[\"bus_interchange\"]==1)).astype(int)\n",
    "    dataframe[\"mrt_nearest_interchange_nil\"]        = ((dataframe[\"mrt_interchange\"]==0) & (dataframe[\"bus_interchange\"]==0)).astype(int)\n",
    "\n",
    "    ## 3. Nearest Bus Stop\n",
    "    dataframe[\"bus_stop_nearest_frm000_150\"] = (dataframe[\"bus_stop_nearest_distance\"]<=150).astype(int)\n",
    "\n",
    "\n",
    "    # (g) Accessibility to Amenities\n",
    "\n",
    "    ## 1. Nearest Mall\n",
    "    dataframe[\"mall_nearest_frm000_500\"]  = ((dataframe[\"mall_nearest_distance\"]>=0) & (dataframe[\"mall_nearest_distance\"]<=500)).astype(int)\n",
    "    dataframe[\"mall_nearest_abv500_1000\"] = ((dataframe[\"mall_nearest_distance\"]>500) & (dataframe[\"mall_nearest_distance\"]<=1000)).astype(int)\n",
    "    dataframe[\"mall_nearest_abv1000\"]     = (dataframe[\"mall_nearest_distance\"]>1000).astype(int)\n",
    "\n",
    "    ## 2. Nearest Hawker Centre\n",
    "    dataframe[\"hawker_nearest_frm000_500\"]  = ((dataframe[\"hawker_nearest_distance\"]>=0) & (dataframe[\"hawker_nearest_distance\"]<=500)).astype(int)\n",
    "    dataframe[\"hawker_nearest_abv500_1000\"] = ((dataframe[\"hawker_nearest_distance\"]>500) & (dataframe[\"hawker_nearest_distance\"]<=1000)).astype(int)\n",
    "    dataframe[\"hawker_nearest_abv1000\"]     = (dataframe[\"hawker_nearest_distance\"]>1000).astype(int)\n",
    "\n",
    "    # 3. Nearest Hawker Centre's Size\n",
    "    dataframe[\"hawker_nearest_size_large\"]  = ((dataframe[\"hawker_food_stalls\"] + dataframe[\"hawker_market_stalls\"])>100).astype(int)\n",
    "\n",
    "\n",
    "    # (h) One-Hot Encoded Features: Unobserved Area-based Features & Time-based Events\n",
    "\n",
    "    # 1. Setup: One-Hot Encoded Features' Category Labels\n",
    "\n",
    "    # Instantiate Sklearn's OneHotEncoder\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "    # Save Category Labels from \"Train\" dataset (for Subsequent Consistent Application to the \"Simulated Test\" and \"Test\" Datasets)\n",
    "    data_train = X_train.copy()\n",
    "    data_train.columns = data_train.columns.str.lower()\n",
    "\n",
    "    cat_features = [\"town\", \"tranc_year\"]\n",
    "    ohe_fit_transform_data_train = ohe.fit(data_train[cat_features])\n",
    "\n",
    "    # 2. Add: One-Hot Encoded Features\n",
    "    dataframe = dataframe.reset_index(drop=True)  # index resetting necessary for subsequent horizontal concatenation\n",
    "\n",
    "    ohe_data = ohe.transform(dataframe[cat_features])\n",
    "    ohe_df   = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out(cat_features))\n",
    "    ohe_df.columns = ohe_df.columns.str.lower()\n",
    "\n",
    "    dataframe = pd.concat([dataframe, ohe_df], axis=1)\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> (b-1) Define Functions: Engineer Complex Features -- Travel Cost to CBD via the MRT Network</b>\n",
    "\n",
    "<br><b>Background</b>\n",
    "\n",
    "The MRT Network Considered\n",
    "* Network as at 2024\n",
    "* HDB resale data spans from 2012 to 2021, and the MRT network has evolved during the period (with [addition of the 'Downtown' line in 2017](https://www.lta.gov.sg/content/ltagov/en/getting_around/public_transport/rail_network/downtown_line.html), and [opening of the 'Thompson-East Coast' line in 2020](https://www.lta.gov.sg/content/ltagov/en/upcoming_projects/rail_expansion/thomson_east_coast_line.html))\n",
    "* We nonetheless considered the network as at 2024, as:\n",
    "    * Data checks reveal that \"name of nearest MRT station\" in the source data is based on the MRT network as at time of the data's preparation (2022), instead of resale transaction year\n",
    "    * We expect home buyers to consider evolution of the MRT network when making a purchase (alongside other future-oriented area development plans)\n",
    "\n",
    "<br> <b>Computation of Travel Cost </b>\n",
    "\n",
    "* Conceptual Definition: Travel Cost to the CBD via the MRT Network\n",
    "    * Travel Cost = Minimum(Number of MRT stations away from a CBD station + Transfer Penalty for Switching MRT Lines)\n",
    "    * 'Transfer Penalty' - Penalty for making a switch modelled as equivalent to travelling to an additional MRT station\n",
    "\n",
    "* Computation Approach\n",
    "    * Utilises [Dijkstra's algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) to construct: `mrt_travel_cost_cbd`\n",
    "    * Implementation of the algorithm is credited to Eryk Kopczyński [(code reference)](https://www.python.org/doc/essays/graphs/), and uses a [deque](https://docs.python.org/3/library/collections.html#collections.deque) from Python's collections module for efficient breadth-first search\n",
    "    * Credit for writing this section of code goes to [Wei Chiong Tan](t-wei-ch.github.io/my-portfolio/)\n",
    "\n",
    "* Definition: CBD Stations \n",
    "\n",
    "    |Line|Station(s)|\n",
    "    |---|---|\n",
    "    |NSL|Raffles Place, City Hall, Marina Bay|\n",
    "    |EWL|Outram Park, Tanjong Pagar, Raffles Place, City Hall|\n",
    "    |CCL|Telok Blangah, Harbourfront, Bayfront, Promenade, Esplanade, Marina Bay|\n",
    "    |DTL|Telok Ayer, Downtown, Bayfront, Promenade|\n",
    "    |TEL|Maxwell, Shenton Way, Marina Bay|\n",
    "\n",
    "<br> <b>Code Implementation</b>\n",
    "\n",
    "* Code for computing 'Travel Cost to CBD via the MRT Network' has been written in a separate script, under: '1_Data/mrt_tools.py'\n",
    "* Codes in this notebook import the script's computation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from Data_Processing_MRT_Tools import mrt_scores_per_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(2) Define Function: Travel Cost to CBD via the MRT Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_mrt_travel_cost_cbd(dataframe):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    # Insert `mrt_travel_cost_cbd` column into `dataframe`\n",
    "    dataframe[\"mrt_travel_cost_cbd\"]   = dataframe.apply(lambda row: mrt_scores_per_station[row[\"mrt_name\"]], axis=1)\n",
    "    dataframe[\"mrt_travel_cost_cbd_2\"] = dataframe[\"mrt_travel_cost_cbd\"]**2\n",
    "\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<b> (b-2) Define Functions: Engineer Complex Features -- Accessibility to 'Branded' Schools</b>\n",
    "\n",
    "<br><b>Background: Definition of 'Branded' Schools</b>\n",
    "\n",
    "* We rely on a classification approach used in a [research study](https://www.childrensociety.org.sg/wp-content/uploads/2022/07/Schools-and-Class-Divide_Research-Monograph-11_FINAL_24-Aug-2016v3.pdf) by the Singapore Children's Society to identify \"branded/elite\" schools:\n",
    "    * Primary Schools: offer the Gifted Education Programme (GEP), are affiliated to Integrated Programme secondary schools, or are government-aided\n",
    "    * Secondary Schools: offer the Integrated Programme, or are autonomous schools\n",
    "\n",
    "<br><b>Code Implementation</b>\n",
    "\n",
    "* Step 1: obtain full list of schools and their geographic co-ordinates\n",
    "* Step 2: specify list of 'branded' schools\n",
    "* Step 3: compute distances of 'branded' schools from resale flats sold, to build a picture of the no. of 'branded' schools within a given geographic radius\n",
    "* Credit for writing this section of code goes to [Wei Chiong Tan](t-wei-ch.github.io/my-portfolio/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(1) Obtain Full List of Schools and their Geographic Coordinates</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build Dictionary of Schools-Geo Coordinates from Source Data\n",
    "\n",
    "# Isolate primary school names and their relevant coordinates to a dictionary\n",
    "pri_sch_dict = df_train_init.loc[:,['pri_sch_name', 'pri_sch_latitude', 'pri_sch_longitude']].to_dict(orient='list')\n",
    "\n",
    "# Isolate secondary school names and their relevant coordinates to a dictionary\n",
    "sec_sch_dict = df_train_init.loc[:,['sec_sch_name', 'sec_sch_latitude', 'sec_sch_longitude']].to_dict(orient='list')\n",
    "\n",
    "# Match schools with their coordinates\n",
    "lst_of_pri_sch_coords = zip(pri_sch_dict['pri_sch_latitude'], pri_sch_dict['pri_sch_longitude'])\n",
    "lst_of_sec_sch_coords = zip(sec_sch_dict['sec_sch_latitude'], sec_sch_dict['sec_sch_longitude'])\n",
    "\n",
    "pri_sch_coords = {name: coords for name, coords in zip(pri_sch_dict['pri_sch_name'], lst_of_pri_sch_coords)}\n",
    "sec_sch_coords = {name: coords for name, coords in zip(sec_sch_dict['sec_sch_name'], lst_of_sec_sch_coords)}\n",
    "\n",
    "# 2. Add Coordinates of Relevant Missing \"Branded\" Schools\n",
    "pri_sch_coords[\"Anglo-Chinese School\"] = (1.31875235, 103.835076922932)\n",
    "pri_sch_coords[\"Raffles Girls' Primary School\"] = (1.33004178, 103.806397828938)\n",
    "pri_sch_coords[\"Singapore Chinese Girls' School\"] = (1.3210897, 103.827867312987)\n",
    "pri_sch_coords[\"Methodist Girls' School\"] = (1.3329500, 103.7825694)\n",
    "\n",
    "sec_sch_coords[\"Nanyang Girls' High School\"] = (1.3305, 103.8024)\n",
    "sec_sch_coords[\"Hwa Chong Institution\"] = (1.32654, 103.803491)\n",
    "sec_sch_coords[\"Saint Joseph's Institution\"] = (1.3236, 103.8273)\n",
    "sec_sch_coords[\"National Junior College\"] = (1.330278, 103.804167)\n",
    "sec_sch_coords[\"NUS High School\"] = (1.306911, 103.769356)\n",
    "sec_sch_coords[\"Singapore Chinese Girls' School\"] = (1.3210897, 103.827867312987)\n",
    "sec_sch_coords[\"Victoria School\"] = (1.308575, 103.927467)\n",
    "sec_sch_coords[\"Maris Stella High School\"] = (1.3421839569999998, 103.8780964)\n",
    "sec_sch_coords[\"Tanjong Katong Girls' School\"] = (1.30785, 103.89619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Geylang Methodist School', (1.317658971, 103.8825037)),\n",
       "             ('Kuo Chuan Presbyterian Primary School',\n",
       "              (1.349783074, 103.8545292)),\n",
       "             ('Keming Primary School', (1.3452450530000002, 103.7562645)),\n",
       "             ('Catholic High School', (1.3547888769999998, 103.8449341)),\n",
       "             ('Naval Base Primary School', (1.4162801530000002, 103.8387977))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: print coordinates of first 5 primary schools in dictionary\n",
    "collections.OrderedDict(list(pri_sch_coords.items())[0: 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Geylang Methodist School', (1.317658971, 103.8825037)),\n",
       "             ('Kuo Chuan Presbyterian Secondary School',\n",
       "              (1.350109648, 103.8548917)),\n",
       "             ('Yusof Ishak Secondary School',\n",
       "              (1.3423337780000002, 103.7600131)),\n",
       "             ('Catholic High School', (1.3547888769999998, 103.8449341)),\n",
       "             ('Orchid Park Secondary School', (1.414888187, 103.8383349))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test: print coordinates of first 5 secondary schools in dictionary\n",
    "collections.OrderedDict(list(sec_sch_coords.items())[0: 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(2) Specify List of 'Branded' Schools</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "branded_pri_schs = ['Anglo-Chinese School',\n",
    "                    'Catholic High School',\n",
    "                    \"CHIJ Saint Nicholas Girls' School\",\n",
    "                    'Henry Park Primary School',\n",
    "                    'Nanyang Primary School',\n",
    "                    \"Raffles Girls' Primary School\",\n",
    "                    'Rosyth School',\n",
    "                    \"Singapore Chinese Girls' School\",\n",
    "                    \"Saint Hilda's Primary School\",\n",
    "                    \"Saint Joseph's Institution Junior\",\n",
    "                    \"Saint Stephen's School\",\n",
    "                    'Tao Nan School',\n",
    "                    'Ai Tong School',\n",
    "                    'Canossa Catholic Primary School',\n",
    "                    'CHIJ',\n",
    "                    'CHIJ Our Lady of Good Counsel',\n",
    "                    'CHIJ Our Lady of The Nativity',\n",
    "                    'CHIJ Our Lady Queen of Peace',\n",
    "                    'Chongfu School',\n",
    "                    'De La Salle School',\n",
    "                    'Fairfield Methodist School',\n",
    "                    'Geylang Methodist School',\n",
    "                    \"Holy Innocents' Primary School\",\n",
    "                    'Hong Wen School',\n",
    "                    'Kheng Cheng School',\n",
    "                    'Kong Hwa School',\n",
    "                    'Kuo Chuan Presbyterian Primary School',\n",
    "                    'Maha Bodhi School',\n",
    "                    'Maris Stella High School',\n",
    "                    'Marymount Convent School',\n",
    "                    'Mee Toh School',\n",
    "                    'Nan Chiau Primary School',\n",
    "                    'Ngee Ann Primary School',\n",
    "                    \"Paya Lebar Methodist Girls' School\",\n",
    "                    'Pei Chun Public School',\n",
    "                    'Pei Hwa Presbyterian Primary School',\n",
    "                    'Poi Ching School',\n",
    "                    'Red Swastika School',\n",
    "                    \"Saint Andrew's Junior School\",\n",
    "                    \"Saint Anthony's Canossian Primary School\",\n",
    "                    \"Saint Gabriel's Primary School\",\n",
    "                    \"Saint Margaret's Primary School\"]\n",
    "\n",
    "branded_sec_schs = ['Anglo-Chinese School',\n",
    "                    'Catholic High School',\n",
    "                    \"Cedar Girls' Secondary School\",\n",
    "                    \"CHIJ Saint Nicholas Girls' School\",\n",
    "                    'Dunman High School',\n",
    "                    'Hwa Chong Institution',\n",
    "                    \"Methodist Girls' School\",\n",
    "                    \"Nanyang Girls' High School\",\n",
    "                    'National Junior College',\n",
    "                    'NUS High School',\n",
    "                    'Raffles Institution',\n",
    "                    \"Raffles Girls' School\",\n",
    "                    'River Valley High School',\n",
    "                    \"Singapore Chinese Girls' School\",\n",
    "                    \"Saint Joseph's Institution\",\n",
    "                    'Temasek Junior College',\n",
    "                    'Victoria School',\n",
    "                    'Anderson Secondary School',\n",
    "                    'Anglican High School',\n",
    "                    'Bukit Panjang Government High School',\n",
    "                    'CHIJ Katong Convent',\n",
    "                    'CHIJ Secondary',\n",
    "                    'Chung Cheng High School',\n",
    "                    'Commonwealth Secondary School',\n",
    "                    \"Crescent Girls' School\",\n",
    "                    'Dunman Secondary School',\n",
    "                    'Fairfield Methodist School',\n",
    "                    'Maris Stella High School',\n",
    "                    'Nan Hua High School',\n",
    "                    'Ngee Ann Secondary School',\n",
    "                    \"Paya Lebar Methodist Girls' School\",\n",
    "                    \"Saint Anthony's Canossian Secondary School\",\n",
    "                    \"Saint Hilda's Secondary School\",\n",
    "                    \"Saint Margaret's Secondary School\",\n",
    "                    \"Tanjong Katong Girls' School\",\n",
    "                    'Tanjong Katong Secondary School',\n",
    "                    'Temasek Secondary School',\n",
    "                    'Xinmin Secondary School',\n",
    "                    'Yishun Town Secondary School',\n",
    "                    'Zhonghua Secondary School']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(3) Compute Distance of 'Branded' schools from Resale Flats Sold, Build Picture of No. of 'Branded' Schools within a given Geographic Radius</b>\n",
    "\n",
    "(a) Define Function: Calculate Distance Between 2 Latitude-Longitude Coordinates\n",
    "\n",
    "<details><summary>Mathematical background of latitude and longitude calculations:</summary>\n",
    "\n",
    "<br><u> Theoretical Challenges </u>\n",
    "\n",
    "As is common knowledge since the circumnavigation of the Earth by the Magellan Expedition in 1519-1522, the Earth is not flat. However, modeling the Earth as a perfect sphere isn't exactly correct either, as the actual [shape of the Earth](https://en.wikipedia.org/wiki/Figure_of_the_Earth) is an oblate spheroid, and an imperfect one at that. This makes [measuring](https://en.wikipedia.org/wiki/Geographical_distance) exact distances on the surface of the Earth slightly challenging, and is one of the major problems that the creators of the Global Positioning System (GPS) had to solve.\n",
    "\n",
    "Even more troubling, while relatively small distances on the surface of the Earth would be reasonably approximated to a small margin of error by using the Pythagorean theorem as the Earth is locally approximated by a flat plane, said theorem only works if the points given are Cartesian coordinates $p_1=(x_1, y_1)$ and $p_2=(x_2, y_2)$. The Pythagorean distance would then be given by $$d(p_1,p_2)=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$$ That is not the case here, as we are given latitude and longitude, which assume that we are working in spherical coordinates. \n",
    "\n",
    "<br><u> Approach Undertaken</u>\n",
    "\n",
    "Specifically, the point with latitude $\\phi$ and longitude $\\lambda$ would correspond to the Cartesian coordinates on the sphere with radius $r$ in 3-dimensional Euclidean space. $$(r\\cos(\\phi)\\cos(\\lambda),\\ r\\cos(\\phi)\\sin(\\lambda),\\ r\\sin(\\phi))$$  On the sphere, the shortest distance between two points would be computed instead by the [great circle distance](https://en.wikipedia.org/wiki/Great-circle_distance), the distance along the great circle on the sphere that connects the two points.\n",
    "\n",
    "A relatively efficient computation for the great circle distance between two points specified by latitude and longitude is achieved by the [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula), which works just fine when two points are close to each other on the sphere, as is per our case for Singapore. Assuming that the latitudes and longitudes are all given in radians, the Haversine formula for the distance $d$ between two points on the sphere with radius $r$ given by latitudes and longitudes $p_1=(\\phi_1, \\lambda_1)$ and $p_2=(\\phi_2, \\lambda_2)$ is given as follows: $$d(p_1, p_2)=r\\cdot\\left(2\\tan^{-1}\\left(\\frac{\\sqrt{a}}{\\sqrt{1-a}}\\right)\\right)$$ where $$a=\\frac{1-\\cos(\\phi_2-\\phi_1)}{2}+\\cos(\\phi_1)\\cos(\\phi_2)\\left(\\frac{1-\\cos(\\lambda_2-\\lambda_1)}{2}\\right)$$ is called the [haversine](https://en.wikipedia.org/wiki/Versine) (or half a versine). \n",
    "\n",
    "This may seem a tad complicated, but it essentially just uses the arc-length formula $d=r\\theta$, and that the computation of $\\theta$ is only more involved due to the inputs being latitude and longitude.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Calculate Distance Between 2 Latitude-Longitude Coordinates using the Haversine formula\n",
    "\n",
    "def haversine_dist(lat_1, long_1, lat_2, long_2, r=6371):\n",
    "\n",
    "    '''Computes the great circle distance between two points `(lat_1, long_1)` and `(lat_2, long_2)` \n",
    "    on a spherical Earth, specified by latitudes `lat_1`, `lat_2` and longitudes `long_1`, `long_2`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `lat_1`: float\n",
    "        Latitude of the first point in degrees\n",
    "    `long_1`: float\n",
    "        Longitude of the first point in degrees\n",
    "    `lat_2`: float\n",
    "        Latitude of the second point in degrees\n",
    "    `long_2`: float\n",
    "        Longitude of the second point in degrees\n",
    "    `r`: float\n",
    "        Radius of the Earth. Default `6371` km.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `dist`: float\n",
    "        Distance between the two points in km.\n",
    "    '''\n",
    "\n",
    "    # convert all latitudes and longitudes to radians\n",
    "    lat_1, long_1, lat_2, long_2 = np.radians(lat_1), np.radians(long_1), np.radians(lat_2), np.radians(long_2)\n",
    "\n",
    "    # calculate latitude and longitude differences\n",
    "    dlat  = lat_2 - lat_1\n",
    "    dlong = long_2 - long_1\n",
    "\n",
    "    # calculate the haversine\n",
    "    haversine = 0.5 * (1 - np.cos(dlat) + np.cos(lat_1)*np.cos(lat_2)*(1 - np.cos(dlong)))\n",
    "\n",
    "    # calculate great circle distance\n",
    "    dist = 2 * r * np.arctan2(np.sqrt(haversine), np.sqrt(1 - haversine))\n",
    "\n",
    "    return dist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Define Function: Identify Distance to 'Branded' Schools, Count No. of 'Branded' Schools within a Given Distance from a Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function: Identify Distance to 'Branded' Schools, Count No. of 'Branded' Schools within a Given Distance from a Coordinate\n",
    "\n",
    "import functools\n",
    "@functools.cache\n",
    "\n",
    "def nearest_landmarks(lat, long, landmark='pri', radius=1.0, output='landmarks'):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    `lat`: float\n",
    "        Latitude of the selected point\n",
    "    \n",
    "    `long`: float\n",
    "        Longitude of the selected point\n",
    "    \n",
    "    `landmark`: string. Default `'pri'`\n",
    "        `'pri'`:       Primary schools\n",
    "        `'brand_pri'`: Branded primary schools\n",
    "        `'sec'`:       Secondary schools\n",
    "        `'brand_sec'`: Branded secondary schools\n",
    "    \n",
    "    `radius`: float\n",
    "        Search radius in km. Default `1.0` km\n",
    "    \n",
    "    `output`: string. Default `'landmarks'`\n",
    "        `'landmarks'`: Outputs a list of `landmark`s that are within a `dist` km radius around `(lat, long)`\n",
    "        `'count'`:     Outputs how many `landmark`s there are within a `dist` km radius around `(lat, long)`\n",
    "        `'data'`:      Outputs a dictionary of `dist: landmark` pairs \n",
    "        `'shortest'`:  Outputs the shortest distance in metres to the nearest `landmark`, sets `radius` parameter to 100\n",
    "    '''\n",
    "    \n",
    "    # radius switch\n",
    "    if output == 'shortest':\n",
    "        radius = 100.0\n",
    "\n",
    "    # initialise empty output dictionary\n",
    "    dist_landmarks = {}\n",
    "\n",
    "    # initialise list of landmarks\n",
    "    lst_landmarks = []\n",
    "\n",
    "    # for conveniently switching between the different landmark types without using if-else statements\n",
    "    \n",
    "    def filter_dict(dic, lst_of_keys):\n",
    "        '''Outputs a filtered subset of the dictionary `dic` with only keys in `lst_of_keys`\n",
    "        '''\n",
    "        filtered_dic = {key: val for key, val in dic.items() if key in lst_of_keys}\n",
    "\n",
    "        return filtered_dic    \n",
    "    \n",
    "    landmark_switch = {'pri': pri_sch_coords,\n",
    "                       'brand_pri': filter_dict(pri_sch_coords, branded_pri_schs),\n",
    "                       'sec': sec_sch_coords,\n",
    "                       'brand_sec': filter_dict(sec_sch_coords, branded_sec_schs)}\n",
    "    \n",
    "    for building in landmark_switch[landmark]:\n",
    "        # retrieve coordinates from the respective dictionary\n",
    "        landmark_lat, landmark_long = landmark_switch[landmark][building]\n",
    "\n",
    "        # compute distance to 5 decimal places\n",
    "        dist = np.round(1000*haversine_dist(lat, long, landmark_lat, landmark_long), 5)\n",
    "\n",
    "        if dist <= 1000*radius:\n",
    "            # append the respective building to the output list\n",
    "            lst_landmarks.append(building)\n",
    "\n",
    "            if dist not in dist_landmarks:\n",
    "                # add school name if there's no school with that distance away\n",
    "                dist_landmarks[dist] = [building]\n",
    "            else:\n",
    "                # else append to the current list value\n",
    "                dist_landmarks[dist].append(building)\n",
    "    \n",
    "    # sort dist_landmarks by distance\n",
    "    dist_landmarks = dict(sorted(dist_landmarks.items()))\n",
    "\n",
    "    if output == 'landmarks':\n",
    "        return lst_landmarks\n",
    "\n",
    "    if output == 'count':\n",
    "        return len(lst_landmarks)\n",
    "    \n",
    "    if output == 'data':\n",
    "        return dist_landmarks\n",
    "    \n",
    "    if output == 'shortest':\n",
    "        # distances are already sorted in increasing order\n",
    "        # the if-else condition accounts for the (unlikely) case where there really are no landmarks within a 100km radius\n",
    "        return list(dist_landmarks.keys())[0] if dist_landmarks else np.nan\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Define Function: Insert into Dataframe -- Distance to Nearest 'Branded' School, Count of No. of 'Branded' Schools within a Given Distance from Resale Unit Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_branded_sch_cols(dataframe):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    '''\n",
    "    Insert branded school columns\n",
    "    ----------\n",
    "    '''\n",
    "    \n",
    "    # school-based variables\n",
    "    for level in ['pri', 'sec']:\n",
    "        dataframe[f'dist_to_nearest_brand_{level}_sch'] = dataframe.apply(lambda row: nearest_landmarks(row['latitude'],\n",
    "                                                                                                        row['longitude'],\n",
    "                                                                                                        landmark=f'brand_{level}',\n",
    "                                                                                                        output='shortest'),\n",
    "                                                                                                        axis=1)\n",
    "        for dist in [1, 2]:\n",
    "            dataframe[f'n_brand_{level}_sch_within_{dist-1}-{dist}km'] = dataframe.apply(lambda row: nearest_landmarks(row['latitude'], \n",
    "                                                                                                                       row['longitude'], \n",
    "                                                                                                                       landmark=f'brand_{level}',\n",
    "                                                                                                                       radius=dist,\n",
    "                                                                                                                       output='count') - \n",
    "                                                                                                     nearest_landmarks(row['latitude'], \n",
    "                                                                                                                       row['longitude'], \n",
    "                                                                                                                       landmark=f'brand_{level}',\n",
    "                                                                                                                       radius=dist-1,\n",
    "                                                                                                                       output='count'),\n",
    "                                                                                                                       axis=1)\n",
    "\n",
    "    return dataframe\n",
    "                                                                                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### <b> Part 4: Define Functions: Others  </b>\n",
    "\n",
    "<b>Overview: Other Functions</b>\n",
    "* (a) Retain Selected Features\n",
    "* (b) Scale Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(a) Define Function: Retain Selected Features</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_selected_features(dataframe):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    dataframe.rename(columns={\"mrt_interchange\":\"mrt_nearest_interchange_mrt\", \"bus_interchange\":\"mrt_nearest_interchange_bus\"}, inplace=\"True\")\n",
    "\n",
    "    id_no = [\"id\"]\n",
    "\n",
    "    selected_y_feature  = [\"resale_price\"]\n",
    "\n",
    "    selected_x_features = [\"floor_area_sqm\",\n",
    "                           \"floor_area_sqm_2\",\n",
    "                           \"floor_level_mid\",\n",
    "                           \"floor_level_mid_2\",\n",
    "                           \"flat_type_dbss\",\n",
    "                           \"flat_type_terrace\",\n",
    "                           \"flat_type_maisonette_loft\",\n",
    "                           \"flat_type_duxton_s1_s2\",\n",
    "                           \"remaining_lease_years\",\n",
    "                           \"remaining_lease_years_2\",\n",
    "                           \"blk_rental_present\",\n",
    "                           \"mrt_nearest_frm000_500\",\n",
    "                           \"mrt_nearest_abv500_1000\",\n",
    "                           \"mrt_nearest_interchange_train_bus\",     # reference cat: \"mrt_nearest_interchange_nil\"\n",
    "                           \"mrt_nearest_interchange_train_only\",\n",
    "                           \"mrt_nearest_interchange_bus_only\",\n",
    "                           \"bus_stop_nearest_frm000_150\",\n",
    "                           \"mall_nearest_frm000_500\",\n",
    "                           \"mall_nearest_abv500_1000\",\n",
    "                           \"hawker_nearest_frm000_500\",\n",
    "                           \"hawker_nearest_abv500_1000\",\n",
    "                           \"hawker_nearest_size_large\",\n",
    "                           \"mrt_travel_cost_cbd\",\n",
    "                           \"mrt_travel_cost_cbd_2\",\n",
    "                           \"n_brand_pri_sch_within_0-1km\",\n",
    "                           \"n_brand_pri_sch_within_1-2km\",\n",
    "                           \"n_brand_sec_sch_within_0-1km\",\n",
    "                           \"n_brand_sec_sch_within_1-2km\",\n",
    "                           \"town_bedok\",                            # reference cat: \"town_ang mo kio\"\n",
    "                           \"town_bishan\",\n",
    "                           \"town_bukit batok\",\n",
    "                           \"town_bukit merah\",\n",
    "                           \"town_bukit panjang\",\n",
    "                           \"town_bukit timah\",\n",
    "                           \"town_central area\",\n",
    "                           \"town_choa chu kang\",\n",
    "                           \"town_clementi\",\n",
    "                           \"town_geylang\",\n",
    "                           \"town_hougang\",\n",
    "                           \"town_jurong east\",\n",
    "                           \"town_jurong west\",\n",
    "                           \"town_kallang/whampoa\",\n",
    "                           \"town_marine parade\",\n",
    "                           \"town_pasir ris\",\n",
    "                           \"town_punggol\",\n",
    "                           \"town_queenstown\",\n",
    "                           \"town_sembawang\",\n",
    "                           \"town_sengkang\",\n",
    "                           \"town_serangoon\",\n",
    "                           \"town_tampines\",\n",
    "                           \"town_toa payoh\",\n",
    "                           \"town_woodlands\",\n",
    "                           \"town_yishun\",\n",
    "                           \"tranc_year_2013\",                       # reference cat: \"tranc_year_2012\"    \n",
    "                           \"tranc_year_2014\",\n",
    "                           \"tranc_year_2015\",\n",
    "                           \"tranc_year_2016\",\n",
    "                           \"tranc_year_2017\",\n",
    "                           \"tranc_year_2018\",\n",
    "                           \"tranc_year_2019\",\n",
    "                           \"tranc_year_2020\",\n",
    "                           \"tranc_year_2021\"\n",
    "                           ]\n",
    "\n",
    "    try: \n",
    "        dataframe = dataframe[id_no + selected_y_feature + selected_x_features]\n",
    "\n",
    "    except:\n",
    "        dataframe = dataframe[id_no + selected_x_features]  # to accomodate absence of 'selected_y_feature' in \"df_test\"\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) Define Function: Scale Numeric Features</b>\n",
    "\n",
    "Purpose & Process of Scaling Numeric Features\n",
    "* Regularisation techniques (Ridge, LASSO) will be applied subsequently in an attempt to improve model generalisability \n",
    "* The application of such techniques requires numeric features to be scaled, in order for estimated coefficients on these terms to be equally influenced by the regularising penalty term (lambda)\n",
    "* Procedurally: scaling factors will be firstly derived from \"training\" data, before being applied to the \"test (simulated)\" and \"test\" datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numeric_features(dataframe):\n",
    "\n",
    "    # 1. Instantiate Standard Scaler\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2. Derive Scaling Factors from \"Training\" Data\n",
    "\n",
    "    ## Implement Data Processing Procedures Prior to Scaling\n",
    "    data_train = df_train.copy()\n",
    "\n",
    "    ## a. Clean & Engineer Features (Simple)\n",
    "    data_train = clean_data(data_train)\n",
    "    data_train = engineer_features_simple(data_train)\n",
    "\n",
    "    ## b. Engineer Features (Complex)\n",
    "    data_train = insert_mrt_travel_cost_cbd(data_train)\n",
    "    data_train = insert_branded_sch_cols(data_train)\n",
    "\n",
    "    ## c. Retain Selected Features\n",
    "    data_train = retain_selected_features(data_train)\n",
    "\n",
    "    ## d. Identify 'Y', 'X(Categorical)' & 'X(Numeric)' Features\n",
    "    y_feature = [\"resale_price\"]\n",
    "\n",
    "    x_cat_features = [\"flat_type_dbss\",\n",
    "                      \"flat_type_terrace\",\n",
    "                      \"flat_type_maisonette_loft\",\n",
    "                      \"flat_type_duxton_s1_s2\",\n",
    "                      \"blk_rental_present\",\n",
    "                      \"mrt_nearest_frm000_500\",\n",
    "                      \"mrt_nearest_abv500_1000\",\n",
    "                      \"mrt_nearest_interchange_train_bus\",\n",
    "                      \"mrt_nearest_interchange_train_only\",\n",
    "                      \"mrt_nearest_interchange_bus_only\",\n",
    "                      \"bus_stop_nearest_frm000_150\",\n",
    "                      \"mall_nearest_frm000_500\",\n",
    "                      \"mall_nearest_abv500_1000\",\n",
    "                      \"hawker_nearest_frm000_500\",\n",
    "                      \"hawker_nearest_abv500_1000\",\n",
    "                      \"hawker_nearest_size_large\"]\n",
    "\n",
    "    for feature in data_train.columns:\n",
    "        if \"town_\" in feature:\n",
    "            x_cat_features.append(feature)\n",
    "        if \"tranc_year_\" in feature:\n",
    "            x_cat_features.append(feature)\n",
    "\n",
    "    x_num_features = [\"floor_area_sqm\",\n",
    "                      \"floor_area_sqm_2\",\n",
    "                      \"floor_level_mid\",\n",
    "                      \"floor_level_mid_2\",\n",
    "                      \"remaining_lease_years\",\n",
    "                      \"remaining_lease_years_2\",\n",
    "                      \"mrt_travel_cost_cbd\",\n",
    "                      \"mrt_travel_cost_cbd_2\",\n",
    "                      \"n_brand_pri_sch_within_0-1km\",\n",
    "                      \"n_brand_pri_sch_within_1-2km\",\n",
    "                      \"n_brand_sec_sch_within_0-1km\",\n",
    "                      \"n_brand_sec_sch_within_1-2km\"]\n",
    "    \n",
    "    # e. Derive and Save 'X(Numeric)' Features' Scaling Factors\n",
    "    data_train_x_num_features = data_train[x_num_features]\n",
    "    data_train_X_num_features_scaled_fit = ss.fit(data_train_x_num_features)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3. Scale Dataframe's Numeric Columns\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    ## a. Split Dataframe into Separate 'Y', 'X(Categorical)' & 'X(Numeric)' Dataframes\n",
    "\n",
    "    try: \n",
    "        dataframe_id_no          = dataframe[\"id\"]\n",
    "        dataframe_y_feature      = dataframe[y_feature]\n",
    "        dataframe_x_cat_features = dataframe[x_cat_features]\n",
    "        dataframe_x_num_features = dataframe[x_num_features]\n",
    "\n",
    "    except: # to accomodate absence of 'Y' in \"df_test\"\n",
    "        dataframe_id_no          = dataframe[\"id\"]\n",
    "        dataframe_x_cat_features = dataframe[x_cat_features]\n",
    "        dataframe_x_num_features = dataframe[x_num_features]        \n",
    "\n",
    "    # b. Scale 'X(Numeric)' Dataframe's Features\n",
    "    dataframe_x_num_features_scaled_array = ss.transform(dataframe_x_num_features)\n",
    "    dataframe_x_num_features_scaled_df = pd.DataFrame(dataframe_x_num_features_scaled_array, columns=ss.get_feature_names_out(x_num_features))\n",
    "\n",
    "    # c. Concatenate 'Y', 'X(Categorical)' & 'X(Numeric)' Dataframes, Re-order Selected Features\n",
    "\n",
    "    id_no      = [\"id\"]\n",
    "\n",
    "    y_feature  = [\"resale_price\"]\n",
    "\n",
    "    x_features = [\"floor_area_sqm\",\n",
    "                  \"floor_area_sqm_2\",\n",
    "                  \"floor_level_mid\",\n",
    "                  \"floor_level_mid_2\",\n",
    "                  \"flat_type_dbss\",\n",
    "                  \"flat_type_terrace\",\n",
    "                  \"flat_type_maisonette_loft\",\n",
    "                  \"flat_type_duxton_s1_s2\",\n",
    "                  \"remaining_lease_years\",\n",
    "                  \"remaining_lease_years_2\",\n",
    "                  \"blk_rental_present\",\n",
    "                  \"mrt_nearest_frm000_500\",\n",
    "                  \"mrt_nearest_abv500_1000\",\n",
    "                  \"mrt_nearest_interchange_train_bus\",\n",
    "                  \"mrt_nearest_interchange_train_only\",\n",
    "                  \"mrt_nearest_interchange_bus_only\",\n",
    "                  \"bus_stop_nearest_frm000_150\",\n",
    "                  \"mall_nearest_frm000_500\",\n",
    "                  \"mall_nearest_abv500_1000\",\n",
    "                  \"hawker_nearest_frm000_500\",\n",
    "                  \"hawker_nearest_abv500_1000\",\n",
    "                  \"hawker_nearest_size_large\",\n",
    "                  \"mrt_travel_cost_cbd\",\n",
    "                  \"mrt_travel_cost_cbd_2\",\n",
    "                  \"n_brand_pri_sch_within_0-1km\",\n",
    "                  \"n_brand_pri_sch_within_1-2km\",\n",
    "                  \"n_brand_sec_sch_within_0-1km\",\n",
    "                  \"n_brand_sec_sch_within_1-2km\"]\n",
    "\n",
    "    for feature in dataframe_x_cat_features.columns:\n",
    "        if \"town_\" in feature:\n",
    "            x_features.append(feature)\n",
    "        if \"tranc_year_\" in feature:\n",
    "            x_features.append(feature)\n",
    "\n",
    "    try:\n",
    "        dataframe = pd.concat([dataframe_id_no, dataframe_y_feature ,dataframe_x_num_features_scaled_df, dataframe_x_cat_features], axis=1)\n",
    "        dataframe = dataframe[id_no + y_feature + x_features]\n",
    "\n",
    "    except: # to accomodate absence of 'Y' in \"df_test\"\n",
    "        dataframe = pd.concat([dataframe_id_no, dataframe_x_num_features_scaled_df, dataframe_x_cat_features], axis=1)\n",
    "        dataframe = dataframe[id_no + x_features]\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### <b> Part 5: Perform Data Processing </b>\n",
    "\n",
    "<b>Overview</b>\n",
    "\n",
    "* The 3 mutually exclusive raw datasets (\"df_train\", \"df_test_sim\", \"df_test\") will be subject to the same data processing procedures\n",
    "* In addition, the processing of each raw dataset will produce two datasets as outputs:\n",
    "\n",
    "    |Dataset Description|X(Numeric) Features|Dataset Suffix|Purpose                                                                                                     |\n",
    "    |-------------------|-------------------|--------------|------------------------------------------------------------------------------------------------------------|\n",
    "    |Processed          |Unscaled           |\"_p\"          |For identifying features that are significantly associated with resale price (practically and statistically)|\n",
    "    |Processed          |Scaled             |\"_ps\"         |For attempting to improve model's generalisability: via implementation of regularisation procedures         |\n",
    "\n",
    "<br>\n",
    "<b>(a) Define Data Processing Function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataframe, scale_num=\"no\"):\n",
    "\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    # Clean & Engineer Features (Simple)\n",
    "    dataframe = clean_data(dataframe)\n",
    "    dataframe = engineer_features_simple(dataframe)\n",
    "\n",
    "    # Engineer Features (Complex)\n",
    "    dataframe = insert_mrt_travel_cost_cbd(dataframe)\n",
    "    dataframe = insert_branded_sch_cols(dataframe)\n",
    "\n",
    "    # Retain Selected Features \n",
    "    dataframe = retain_selected_features(dataframe)\n",
    "\n",
    "    if scale_num==\"no\":\n",
    "        return dataframe\n",
    "    \n",
    "    if scale_num==\"yes\": # Scale Numeric Features\n",
    "        dataframe = scale_numeric_features(dataframe)\n",
    "        return dataframe       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(b) Process Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_p  = process_data(df_train, scale_num=\"no\")\n",
    "df_train_ps = process_data(df_train, scale_num=\"yes\")\n",
    "\n",
    "df_test_sim_p  = process_data(df_test_sim, scale_num=\"no\")\n",
    "df_test_sim_ps = process_data(df_test_sim, scale_num=\"yes\")\n",
    "\n",
    "df_test_p  = process_data(df_test, scale_num=\"no\")\n",
    "df_test_ps = process_data(df_test, scale_num=\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>(c) Export Data as CSV Files</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define: Dictionary of Dataframe Names & Dataframes\n",
    "data = {\"df_train_p\":df_train_p,\n",
    "        \"df_train_ps\":df_train_ps,\n",
    "        \"df_test_sim_p\":df_test_sim_p,\n",
    "        \"df_test_sim_ps\":df_test_sim_ps,\n",
    "        \"df_test_p\":df_test_p,\n",
    "        \"df_test_ps\":df_test_ps\n",
    "        }\n",
    "\n",
    "# Export Data as CSV Files\n",
    "for df_name, df in data.items():\n",
    "    path = f\"1_Data\\{df_name}.csv\"\n",
    "    df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
